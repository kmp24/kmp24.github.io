{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrs\n",
    "from pycrs import parser\n",
    "from fiona.crs import from_epsg\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.plot import show, show_hist\n",
    "from rasterstats import zonal_stats\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the files to be processed\n",
    "data_dir = r'D:\\data'    \n",
    "rasterfile = os.path.join(r'D:\\data\\rasterdata')\n",
    "pdata = gpd.GeoDataFrame.from_file(os.path.join(data_dir,'polygons.gpkg'))\n",
    "\n",
    "#directory for output tiff\n",
    "ddir = data_dir\n",
    "\n",
    "# epsg of the datasets (should be projected)\n",
    "EPSG = 32610\n",
    "\n",
    "# output file name\n",
    "outfile = 'polygons_area.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(gdf):\n",
    "    # Function to parse features from GeoDataFrame to rasterio\n",
    "    import json\n",
    "    return [json.loads(gdf.to_json())['features'][0]['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ogr\n",
    "def fractional_pixel_weights(fsrc, geom):\n",
    "\n",
    "    gt = fsrc.transform\n",
    "    xs = np.arange(gt[2], gt[2] +  gt[0]* (1 + fsrc.shape[1]), gt[0])\n",
    "    ys = np.arange(gt[5], gt[5] +  gt[4]* (1 + fsrc.shape[0]), gt[4])\n",
    "\n",
    "    # Convert geom into ogr geometry\n",
    "    geom_ogr = ogr.CreateGeometryFromWkt(geom.to_wkt())\n",
    "    #geom_ogr = shapely.wkt.loads(geom)\n",
    "\n",
    "    # Loop through each grid cell, compute the intersecting area\n",
    "    overlapping_areas = np.empty((len(ys)-1, len(xs)-1))\n",
    "    for ix in range(len(xs)-1):\n",
    "        xmin = xs[ix]\n",
    "        xmax = xs[ix + 1]\n",
    "        for iy in range(len(ys)-1):\n",
    "            ymax = ys[iy]\n",
    "            ymin = ys[iy + 1]\n",
    "\n",
    "            # Intersecting area\n",
    "            coords_wkt = \"POLYGON ((\" + str(xmin) + ' ' + str(ymax) + ', ' + str(xmax) + ' ' + str(ymax) + ', ' + str(xmax) + ' ' + str(ymin) + ', ' + str(xmin) + ' ' + str(ymin) + ', ' + str(xmin) + ' ' + str(ymax) + \"))\"\n",
    "            polycell = ogr.CreateGeometryFromWkt(coords_wkt)\n",
    "\n",
    "            overlapping_areas[iy, ix] = polycell.Intersection(geom_ogr).Area()\n",
    "            \n",
    "\n",
    "    # Ratio of overlapped area to pixel area\n",
    "    #frac_intersected = (overlapping_areas / (abs(gt[0] * gt[4])))\n",
    "    \n",
    "    # Area of overlap polygon/pixels - 30m resolution\n",
    "    frac_intersected = (overlapping_areas / (abs(gt[0] * gt[4]))) * 900\n",
    "\n",
    "    return frac_intersected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from osgeo import gdalnumeric\n",
    "import sys\n",
    "import time\n",
    "\n",
    "A = time.time()\n",
    "B = []\n",
    "\n",
    "n = 0\n",
    "\n",
    "area_totals = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "\n",
    "pdata['minx'], pdata['miny'], pdata['maxx'], pdata['maxy'] = pdata.bounds['minx'], pdata.bounds['miny'],pdata.bounds['maxx'],pdata.bounds['maxy']\n",
    "\n",
    "with rasterio.open(rasterfile) as src:\n",
    "    for feat in zip(pdata['id'], pdata['geometry']):\n",
    "\n",
    "        # subset the gdf to process one polygon at a time\n",
    "        gdf = pdata.iloc[n]\n",
    "        fileid = gdf['id']\n",
    "        print n\n",
    "\n",
    "        # Set the geometry field to the polygon to be analyzed\n",
    "        geofield = gdf['geometry']\n",
    "\n",
    "        r = rasterio.mask.mask(src, geofield, crop=True, filled=False)\n",
    "        \n",
    "        out_name = 'raster'\n",
    "        \n",
    "        # create bounding box to clip raster\n",
    "        minx, miny, maxx, maxy = gdf['minx'], gdf['miny'], gdf['maxx'], gdf['maxy']\n",
    "        bbox = box(minx, miny, maxx, maxy)\n",
    "        geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=from_epsg(EPSG))\n",
    "        coords = getFeatures(geo)\n",
    "        \n",
    "        # clip the raster based on the extent of the polygon\n",
    "        #print n, coords\n",
    "        out_img, out_transform = mask(src, coords, crop=True, filled=False)\n",
    "        \n",
    "        # update metadata\n",
    "        out_meta = src.meta.copy()\n",
    "        crs = fiona.crs.from_epsg(EPSG)\n",
    "        out_meta.update({\"driver\": \"GTiff\", \"height\": out_img.shape[1],\"width\": out_img.shape[2],\"transform\": out_transform,\"crs\": crs})\n",
    "        \n",
    "        # output the tiff\n",
    "        out_tif = os.path.join(ddir, 'raster.tiff')\n",
    "        with rasterio.open(out_tif, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_img) \n",
    "            \n",
    "            # run the analysis for area cover\n",
    "            x = fractional_pixel_weights(dest, geofield)\n",
    "            \n",
    "            #close the file\n",
    "            dest.close()\n",
    "            n = n + 1\n",
    "        \n",
    "        # Now iterate through each cell in both arrays and summarize the area for each value per pixel   \n",
    "        # Open the temp clipped raster and get the array values for each cell\n",
    "        raster = gdal.Open(out_tif)\n",
    "        rarray = np.array(raster.GetRasterBand(1).ReadAsArray())\n",
    "        \n",
    "        # count the number of cells to loop through to retrieve values\n",
    "        nums = len(x)\n",
    "        \n",
    "        for ynum in range(0,nums):\n",
    "            for xnum in range(0,nums):\n",
    "                try:\n",
    "                    val1 = rarray[xnum,ynum]\n",
    "                    val1area = x[xnum,ynum]\n",
    "                    \n",
    "                    # Append the values to the dataframe\n",
    "                    df['Value'], df['Area'], df['ID'] = val1, val1area, fileid\n",
    "                    areatotals = df.append(pd.Series([val1,val1area,fileid], index=df.columns), ignore_index=True)\n",
    "                    area_totals = area_totals.append(areatotals)\n",
    "                    \n",
    "                except IndexError as e:\n",
    "                    a = 1\n",
    "        del raster\n",
    "                \n",
    "    print area_totals.head()\n",
    "    B.append(time.time()-A)\n",
    "    print B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to sum area for each value\n",
    "update_totals = area_totals.groupby(['recID','Value'], as_index=False)[['Area']].sum()\n",
    "update_totals = update_totals.pivot(index=update_totals.recID, columns='Value')['Area'].fillna(0)\n",
    "#update_totals = update_totals.rename(columns={1:'Sample_Value_Name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_totals.to_csv(outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
